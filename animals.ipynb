{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning in the Eye Tracking World \n",
    "#### the tutorial presented during ETRA 2021 (https://etra.acm.org/2021/acceptedtutorials.html)\n",
    "#### the code downloaded from: https://github.com/kasprowski/etra2021\n",
    "@author: pawel@kasprowski.pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection._split import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "if not os.path.exists(\"animals_img\"):\n",
    "    os.makedirs(\"animals_img\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "#r = requests.get(\"https://raw.githubusercontent.com/kasprowski/etra2021/main/emvic/emvic.data\", allow_redirects=True)\n",
    "r = requests.get(\"http://www.kasprowski.pl/tutorial/animals.zip\", allow_redirects=True)\n",
    "open('animals.zip', 'wb').write(r.content)\n",
    "print(\"Downloaded animals.zip\")\n",
    "with zipfile.ZipFile(\"animals.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"animals\")\n",
    "print(\"Uzipped to /animals directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and convert it to sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: (5757, 20, 2)\n",
      "Labels: (5757, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-d80f17cc5c58>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  samples = np.array(samples)\n"
     ]
    }
   ],
   "source": [
    "def load_files(indir):\n",
    "    samples = []\n",
    "    for file in os.listdir(indir):\n",
    "        if file.endswith(\"csv\"):\n",
    "            samples.append(np.genfromtxt(os.path.join(indir, file), delimiter=','))\n",
    "    samples = np.array(samples)\n",
    "    return samples\n",
    "\n",
    "# Turns one sample of length N into (N-sequence_dim) samples of length sequence_dim\n",
    "# (only if sequence_lag==1!)\n",
    "def make_sequences(samples, sequence_dim = 20, sequence_lag = 1):\n",
    "    nsamples = []\n",
    "    nlabels = []\n",
    "    for sample in samples:\n",
    "        for i in range(0,len(sample)-sequence_dim-1,sequence_lag):\n",
    "            nsample = np.zeros((sequence_dim,2))\n",
    "            for j in range(i,i+sequence_dim):\n",
    "                nsample[j-i,0] = sample[j,1]\n",
    "                nsample[j-i,1] = sample[j,2]\n",
    "            nsamples.append(nsample)\n",
    "            nlabels.append(sample[i+sequence_dim,1:])\n",
    "    samples = np.array(nsamples, dtype=\"float\")\n",
    "    labels = np.array(nlabels)\n",
    "    return samples,labels\n",
    "\n",
    "samples = load_files(\"animals\")\n",
    "sequence_dim=20\n",
    "sequence_lag=1\n",
    "    \n",
    "samples, labels = make_sequences(samples, sequence_dim, sequence_lag)\n",
    "print(\"Samples:\",samples.shape)\n",
    "print(\"Labels:\",labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 20, 128)           67072     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 207,042\n",
      "Trainable params: 207,042\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128,input_shape=(sequence_dim,2),return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(64))\n",
    "model.add(Dense(2))\n",
    "model.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide the dataset into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainSamples, testSamples, trainLabels, testLabels) = train_test_split(samples, labels, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the ground truth image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to /animals_img\n"
     ]
    }
   ],
   "source": [
    "imname = \"animal-11\"    \n",
    "image = cv2.imread(\"animals/{}.jpg\".format(imname))\n",
    "# create the ground truth image with all train gazes\n",
    "for j in range(len(trainLabels)):\n",
    "    s = trainLabels[j]\n",
    "    cv2.circle(image,(int(s[0]),int(s[1])),10,(255,0,0),3)\n",
    "cv2.imwrite(\"animals_img/{}_truth.jpg\".format(imname),image)\n",
    "    \n",
    "print(\"Image saved to /animals_img\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model and save the results after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration: 0\n",
      "39/39 [==============================] - 2s 59ms/step - loss: 702.0654 - mae: 702.0654 - val_loss: 647.8571 - val_mae: 647.8571\n",
      "==================================================\n",
      "Iteration: 1\n",
      "39/39 [==============================] - 2s 60ms/step - loss: 576.4348 - mae: 576.4348 - val_loss: 492.1218 - val_mae: 492.1218\n",
      "==================================================\n",
      "Iteration: 2\n",
      "39/39 [==============================] - 2s 63ms/step - loss: 399.2912 - mae: 399.2912 - val_loss: 303.9146 - val_mae: 303.9146\n",
      "==================================================\n",
      "Iteration: 3\n",
      "39/39 [==============================] - 3s 67ms/step - loss: 270.9413 - mae: 270.9413 - val_loss: 255.0103 - val_mae: 255.0103\n",
      "==================================================\n",
      "Iteration: 4\n",
      "39/39 [==============================] - 3s 66ms/step - loss: 250.4909 - mae: 250.4909 - val_loss: 246.1546 - val_mae: 246.1546\n",
      "==================================================\n",
      "Iteration: 5\n",
      "39/39 [==============================] - 4s 90ms/step - loss: 237.3871 - mae: 237.3871 - val_loss: 228.7539 - val_mae: 228.7539\n",
      "==================================================\n",
      "Iteration: 6\n",
      "39/39 [==============================] - 3s 86ms/step - loss: 221.3777 - mae: 221.3777 - val_loss: 216.0527 - val_mae: 216.0527\n",
      "==================================================\n",
      "Iteration: 7\n",
      "39/39 [==============================] - 3s 69ms/step - loss: 209.3732 - mae: 209.3732 - val_loss: 204.9191 - val_mae: 204.9191\n",
      "==================================================\n",
      "Iteration: 8\n",
      "39/39 [==============================] - 3s 67ms/step - loss: 199.5353 - mae: 199.5353 - val_loss: 196.2719 - val_mae: 196.2719\n",
      "==================================================\n",
      "Iteration: 9\n",
      "39/39 [==============================] - 3s 65ms/step - loss: 188.1853 - mae: 188.1853 - val_loss: 183.3242 - val_mae: 183.3242\n",
      "==================================================\n",
      "Iteration: 10\n",
      "39/39 [==============================] - 3s 66ms/step - loss: 175.3135 - mae: 175.3135 - val_loss: 170.9805 - val_mae: 170.9805\n",
      "==================================================\n",
      "Iteration: 11\n",
      "39/39 [==============================] - 3s 72ms/step - loss: 161.7896 - mae: 161.7896 - val_loss: 158.6253 - val_mae: 158.6253\n",
      "==================================================\n",
      "Iteration: 12\n",
      "39/39 [==============================] - 3s 67ms/step - loss: 152.0106 - mae: 152.0106 - val_loss: 159.8148 - val_mae: 159.8148\n",
      "==================================================\n",
      "Iteration: 13\n",
      "39/39 [==============================] - 3s 65ms/step - loss: 137.3147 - mae: 137.3147 - val_loss: 130.4359 - val_mae: 130.4359\n",
      "==================================================\n",
      "Iteration: 14\n",
      "39/39 [==============================] - 2s 63ms/step - loss: 126.2623 - mae: 126.2623 - val_loss: 128.9698 - val_mae: 128.9698\n",
      "==================================================\n",
      "Iteration: 15\n",
      "39/39 [==============================] - 2s 63ms/step - loss: 117.0278 - mae: 117.0278 - val_loss: 114.8829 - val_mae: 114.8829\n",
      "==================================================\n",
      "Iteration: 16\n",
      "39/39 [==============================] - 3s 64ms/step - loss: 105.6678 - mae: 105.6678 - val_loss: 104.3202 - val_mae: 104.3202\n",
      "==================================================\n",
      "Iteration: 17\n",
      "39/39 [==============================] - 2s 62ms/step - loss: 95.0948 - mae: 95.0948 - val_loss: 90.5677 - val_mae: 90.5677\n",
      "==================================================\n",
      "Iteration: 18\n",
      "39/39 [==============================] - 2s 62ms/step - loss: 87.6344 - mae: 87.6344 - val_loss: 87.0416 - val_mae: 87.0416\n",
      "==================================================\n",
      "Iteration: 19\n",
      "39/39 [==============================] - 2s 62ms/step - loss: 82.0166 - mae: 82.0166 - val_loss: 83.9968 - val_mae: 83.9968\n",
      "==================================================\n",
      "Iteration: 20\n",
      "39/39 [==============================] - 2s 63ms/step - loss: 76.6077 - mae: 76.6077 - val_loss: 82.4272 - val_mae: 82.4272\n",
      "==================================================\n",
      "Iteration: 21\n",
      "39/39 [==============================] - 3s 67ms/step - loss: 73.3385 - mae: 73.3385 - val_loss: 76.8900 - val_mae: 76.8900\n",
      "==================================================\n",
      "Iteration: 22\n",
      "39/39 [==============================] - 3s 68ms/step - loss: 67.8529 - mae: 67.8529 - val_loss: 69.7448 - val_mae: 69.7448\n",
      "==================================================\n",
      "Iteration: 23\n",
      "39/39 [==============================] - 2s 62ms/step - loss: 66.0169 - mae: 66.0169 - val_loss: 64.5690 - val_mae: 64.5690\n",
      "==================================================\n",
      "Iteration: 24\n",
      "39/39 [==============================] - 3s 72ms/step - loss: 61.7702 - mae: 61.7702 - val_loss: 71.7593 - val_mae: 71.7593\n",
      "==================================================\n",
      "Iteration: 25\n",
      "39/39 [==============================] - 3s 73ms/step - loss: 63.0715 - mae: 63.0715 - val_loss: 67.5976 - val_mae: 67.5976\n",
      "==================================================\n",
      "Iteration: 26\n",
      "39/39 [==============================] - 3s 70ms/step - loss: 58.5440 - mae: 58.5440 - val_loss: 61.0218 - val_mae: 61.0218\n",
      "==================================================\n",
      "Iteration: 27\n",
      "39/39 [==============================] - 3s 68ms/step - loss: 57.4063 - mae: 57.4063 - val_loss: 60.4624 - val_mae: 60.4624\n",
      "==================================================\n",
      "Iteration: 28\n",
      "39/39 [==============================] - 3s 66ms/step - loss: 54.4219 - mae: 54.4219 - val_loss: 56.9461 - val_mae: 56.9461\n",
      "==================================================\n",
      "Iteration: 29\n",
      "39/39 [==============================] - 3s 76ms/step - loss: 59.1107 - mae: 59.1107 - val_loss: 64.3707 - val_mae: 64.3707\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "for e in range(EPOCHS):\n",
    "    print(\"=\"*50)\n",
    "    print(\"Iteration: {}\".format(e))\n",
    "    model.fit(trainSamples, trainLabels, validation_data=(testSamples, testLabels), epochs=1\n",
    "              , batch_size=128, verbose=1)\n",
    "\n",
    "    predictions = model.predict(testSamples)\n",
    "\n",
    "    # create and save image with all current predictions\n",
    "    image = cv2.imread(\"animals/{}.jpg\".format(imname))\n",
    "    cv2.line(image,(0,0),(200,200),(255,255,255),2)\n",
    "    for p in predictions:    \n",
    "        cv2.circle(image,(int(p[0]),int(p[1])),10,(0,255,0),3)\n",
    "    cv2.imwrite(\"animals_img/{}_e{:02d}.jpg\".format(imname,e),image)\n",
    "\n",
    "model.save(\"model_rnn.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
