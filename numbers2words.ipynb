{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning in the Eye Tracking World \n",
    "#### the tutorial presented during ETRA 2021 (https://etra.acm.org/2021/acceptedtutorials.html)\n",
    "#### the code downloaded from: https://github.com/kasprowski/etra2021\n",
    "@author: pawel@kasprowski.pl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translating a number into text using RNN\n",
    "- input: number in range(0,DATASE_SIZE)\n",
    "- output: text\n",
    "\n",
    "Examples: \n",
    "- input: 234, output: two hundred thirty four\n",
    "- input: 6, output: six\n",
    "\n",
    "The code in number2word.py taken from: https://www.codesansar.com/python-programming-examples/number-words-conversion-no-library-used.htm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import RNN, LSTM, RepeatVector\n",
    "import numpy as np\n",
    "from number2word import getWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 30, 16)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 30, 128)           74240     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 30, 128)           131584    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30, 128)           131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30, 26)            3354      \n",
      "=================================================================\n",
      "Total params: 340,794\n",
      "Trainable params: 340,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_SEQUENCE_LEN=30\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=1) ) \n",
    "model.add(RepeatVector(OUTPUT_SEQUENCE_LEN)) #length of the text\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dense(26,activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\",metrics=['accuracy','mae'])\n",
    "num_epochs = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample (input): 5\n",
      "Label ['f', 'i', 'v', 'e', ' ', ' ']\n",
      "Label encoded (output):\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]]\n",
      "(200, 30, 26)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-64cf8ab9d612>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  labels = np.array(labels)\n"
     ]
    }
   ],
   "source": [
    "DATASET_SIZE=200\n",
    "\n",
    "samples = []\n",
    "labels = []\n",
    "\n",
    "import random\n",
    "\n",
    "for i in range(DATASET_SIZE):\n",
    "    samples.append(i)\n",
    "    #words = lslownie(i)\n",
    "    words = getWords(i)\n",
    "    labels.append(list(words))\n",
    "\n",
    "samples = np.array(samples)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Sample (input):\",samples[5])\n",
    "print(\"Label\",labels[5])\n",
    "\n",
    "codes = ' abcdefghijklmnoprstuvwxyz'\n",
    "\n",
    "nlabels = np.zeros((DATASET_SIZE,OUTPUT_SEQUENCE_LEN,len(codes)))\n",
    "for i in range(DATASET_SIZE):\n",
    "    for j in range(OUTPUT_SEQUENCE_LEN):\n",
    "        if j>=len(labels[i]): \n",
    "                nlabels[i][j][0]=1\n",
    "                continue\n",
    "        x = labels[i][j]\n",
    "        #print(x)\n",
    "        index = codes.index(x)\n",
    "        nlabels[i][j][index] = 1\n",
    "print(\"Label encoded (output):\\n\",nlabels[123])\n",
    "labels = nlabels\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 100  test samples 100\n"
     ]
    }
   ],
   "source": [
    "TRAINING_SIZE = .5\n",
    "from sklearn.model_selection import train_test_split\n",
    "(trainSamples, testSamples, trainLabels, testLabels) = train_test_split(samples, labels,train_size=TRAINING_SIZE)\n",
    "print('Training samples:',len(trainSamples),' test samples',len(testSamples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 100 samples 50 epochs and batch_size= 50\n",
      "Epochs so far 0\n",
      "\n",
      "Epoch 50 - loss = 1.269, loss improvement = 1.819\n",
      "127 -> nnhhhundddd   ttt\n",
      "167 -> nnhhhunddddde  tttt\n",
      "183 -> nnhhhunddddde  tttt\n",
      "163 -> nnhhhunddddde  tttt\n",
      "188 -> nnhhhunddddde  tttt\n",
      "36 -> nn tttt\n",
      "68 -> nnn\n",
      "45 -> nn  tt\n",
      "62 -> nn\n",
      "190 -> nnhhhuuddddde  tttt\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 100 - loss = 0.993, loss improvement = 0.282\n",
      "190 -> nee hundred  iittt\n",
      "84 -> nne tyy\n",
      "146 -> nee hundred  itttt\n",
      "73 -> nnetty\n",
      "119 -> nee hundred  tttt\n",
      "29 -> nntttt\n",
      "105 -> nne huuddd\n",
      "89 -> nne  yy\n",
      "72 -> nnetty\n",
      "66 -> nnetty\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 150 - loss = 0.778, loss improvement = 0.212\n",
      "41 -> oiity   ee\n",
      "181 -> one hundred sietty\n",
      "158 -> one hundred fiett\n",
      "30 -> oiitty  iee\n",
      "9 -> oieee\n",
      "100 -> one hyn e\n",
      "185 -> one hundred sietty\n",
      "156 -> one hundred fiett\n",
      "46 -> oiity   ee\n",
      "184 -> one hundred sietty\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 200 - loss = 0.642, loss improvement = 0.134\n",
      "157 -> one hundred fihty   e\n",
      "175 -> one hundred sieety\n",
      "132 -> one hundred tierty   e\n",
      "171 -> one hundred sietty   e\n",
      "133 -> one hundred tirrty   e\n",
      "90 -> oneety\n",
      "69 -> oiety\n",
      "111 -> one hundred tiee\n",
      "181 -> one hundred sieety\n",
      "19 -> oiiete\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 250 - loss = 0.591, loss improvement = 0.048\n",
      "175 -> one hundred sieety  iee\n",
      "194 -> one hundred sieety  iie\n",
      "106 -> one hundred tieet\n",
      "193 -> one hundred sieety  iie\n",
      "100 -> one hundred tiee\n",
      "146 -> one hundred fivty   rr\n",
      "5 -> oie\n",
      "30 -> tiirty  iee\n",
      "140 -> one hundred firty  irr\n",
      "165 -> one hundred sieety   i\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 300 - loss = 0.536, loss improvement = 0.127\n",
      "64 -> oixty   r\n",
      "44 -> tirty  ive\n",
      "45 -> tirty  ive\n",
      "42 -> tirty  ive\n",
      "133 -> one hundred torrty  ie\n",
      "35 -> tiirty  ive\n",
      "13 -> tieeeee\n",
      "39 -> tirrt   vee\n",
      "73 -> oivety  o r\n",
      "177 -> one hundred sivety   o\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 350 - loss = 0.448, loss improvement = 0.074\n",
      "74 -> oivent    re\n",
      "137 -> one hundred torrty  eee\n",
      "130 -> one hundred twenty  e\n",
      "68 -> sixty  o r\n",
      "30 -> thirty   ee\n",
      "185 -> one hundred sivety\n",
      "156 -> one hundred fifty   re\n",
      "176 -> one hundred sivety   o\n",
      "80 -> oighty  oee\n",
      "121 -> one hundred teenty en\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 400 - loss = 0.410, loss improvement = 0.041\n",
      "67 -> sixty  or\n",
      "146 -> one hundred forty  ere\n",
      "195 -> one hundred ninety  ive\n",
      "110 -> one hundred tig\n",
      "30 -> thirty\n",
      "148 -> one hundred forty  ere\n",
      "33 -> thirty  ive\n",
      "44 -> tirty  ive\n",
      "91 -> oighty  iu\n",
      "26 -> thinty six\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 450 - loss = 0.377, loss improvement = 0.035\n",
      "24 -> twenty twx\n",
      "151 -> one hundred fifty tir\n",
      "101 -> one hundred twr\n",
      "190 -> one hundred ninety  ive\n",
      "4 -> swvn\n",
      "21 -> twenty nn\n",
      "195 -> one hundred ninety  ive\n",
      "89 -> oigety  iu\n",
      "102 -> one hundred twr\n",
      "45 -> tirty  ive\n",
      "Correct 0 of 200  =  0.0\n",
      "\n",
      "Epoch 500 - loss = 0.420, loss improvement =-0.034\n",
      "180 -> one hundred sivety\n",
      "11 -> tieee\n",
      "137 -> one hundred forty     e\n",
      "147 -> one hundred fofty thu\n",
      "97 -> one ty eig\n",
      "123 -> one hundred twenty ni\n",
      "34 -> thiry   eee\n",
      "190 -> one hundred ninety  iu\n",
      "25 -> thenty six\n",
      "25 -> thenty six\n",
      "Correct 0 of 200  =  0.0\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=50\n",
    "BATCH_SIZE = int(len(trainSamples)/2)\n",
    "print('Training with',len(trainSamples),'samples',EPOCHS,'epochs and batch_size=',BATCH_SIZE)\n",
    "print(\"Epochs so far\",num_epochs)\n",
    "for x in range(10):\n",
    "    H = model.fit(trainSamples, trainLabels, epochs=EPOCHS,verbose=0,batch_size=BATCH_SIZE)\n",
    "    num_epochs += EPOCHS\n",
    "    print()\n",
    "    print(\"Epoch {} - loss ={:6.3f}, loss improvement ={:6.3f}\".\n",
    "          format(num_epochs,H.history['loss'][-1], H.history['loss'][0]-H.history['loss'][-1]))\n",
    "    pred = model.predict(samples)\n",
    "    res = pred.argmax(axis=2)\n",
    "    c,l,p = check_model()\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> oon  \n",
      "1 -> one  [T]\n",
      "2 -> swo  [T]\n",
      "3 -> swo  \n",
      "4 -> ewvn  \n",
      "5 -> eevn  \n",
      "6 -> eive  \n",
      "7 -> eiven  [T]\n",
      "8 -> sige  [T]\n",
      "9 -> sive  [T]\n",
      "10 -> tiee  \n",
      "11 -> tieee  \n",
      "12 -> tielee  [T]\n",
      "13 -> tieteeen  [T]\n",
      "14 -> tieteen  \n",
      "15 -> tieteen  \n",
      "16 -> tweteen  [T]\n",
      "17 -> tweteen  \n",
      "18 -> tweteen  \n",
      "19 -> twetteen  [T]\n",
      "20 -> tweete nn  \n",
      "21 -> twenty on  [T]\n",
      "22 -> twenty two  [T]\n",
      "23 -> twenty tw  \n",
      "24 -> thenty six  \n",
      "25 -> thenty six  \n",
      "26 -> thenty sev  [T]\n",
      "27 -> thenty sev  [T]\n",
      "28 -> thenty  e  \n",
      "29 -> thirty  \n",
      "30 -> thirty  [T]\n",
      "31 -> thirty  [T]\n",
      "32 -> thirty   ee  \n",
      "33 -> thirty  ive  [T]\n",
      "34 -> thiry   eee  \n",
      "35 -> thrty   eee  [T]\n",
      "36 -> thrty   vee  \n",
      "37 -> thrty  ive  [T]\n",
      "38 -> thrty  ive  \n",
      "39 -> thrty  ive  [T]\n",
      "40 -> thrty sive  [T]\n",
      "41 -> thrty sive  \n",
      "42 -> thrty sive  \n",
      "43 -> tirty sive  [T]\n",
      "44 -> firty sive  \n",
      "45 -> firty sive  [T]\n",
      "46 -> firty  ive  \n",
      "47 -> fifty  ive  [T]\n",
      "48 -> fifty  hve  \n",
      "49 -> fifty  h e  \n",
      "50 -> fifty  h  [T]\n",
      "51 -> fifty  h  \n",
      "52 -> fifty  h  \n",
      "53 -> fifty  h  [T]\n",
      "54 -> sifty  h  [T]\n",
      "55 -> sifty  h  \n",
      "56 -> sifty  h  [T]\n",
      "57 -> sifty  h  \n",
      "58 -> sifty sh  [T]\n",
      "59 -> sixty oh  \n",
      "60 -> sixty o  [T]\n",
      "61 -> sixty o  [T]\n",
      "62 -> sixty oo  \n",
      "63 -> sixty so  [T]\n",
      "64 -> sixty  o  [T]\n",
      "65 -> sixty  o  \n",
      "66 -> sixty  o  \n",
      "67 -> sivtyy  [T]\n",
      "68 -> siveny   u  \n",
      "69 -> siventy  \n",
      "70 -> siventy  hue  [T]\n",
      "71 -> siventy  hue  \n",
      "72 -> siventy  hue  \n",
      "73 -> siventy thue  [T]\n",
      "74 -> siventy thve  [T]\n",
      "75 -> siventy tove  \n",
      "76 -> siventy to e  \n",
      "77 -> siventy nn  [T]\n",
      "78 -> sighty  nn  \n",
      "79 -> sighty tnn  [T]\n",
      "80 -> sighty tnn  \n",
      "81 -> sighty ton  [T]\n",
      "82 -> oighty tou  [T]\n",
      "83 -> oighty tou  [T]\n",
      "84 -> oighty tou  [T]\n",
      "85 -> oighty tou  \n",
      "86 -> oighty tou  [T]\n",
      "87 -> oighty  iu  [T]\n",
      "88 -> oighty  iu  [T]\n",
      "89 -> oigety  iu  \n",
      "90 -> oigety  iu  [T]\n",
      "91 -> oinety  iu  \n",
      "92 -> oinety  iu  [T]\n",
      "93 -> onnety  iu  \n",
      "94 -> onnety  iu  [T]\n",
      "95 -> oneety  ig  \n",
      "96 -> oneety eig  \n",
      "97 -> one ty eig  \n",
      "98 -> one hy dig  [T]\n",
      "99 -> one hundred t  \n",
      "100 -> one hundred tw  \n",
      "101 -> one hundred two  \n",
      "102 -> one hundred twx  [T]\n",
      "103 -> one hundred twx  [T]\n",
      "104 -> one hundred tix  \n",
      "105 -> one hundred tig  \n",
      "106 -> one hundred tig  [T]\n",
      "107 -> one hundred tig  \n",
      "108 -> one hundred tig  [T]\n",
      "109 -> one hundred tige  [T]\n",
      "110 -> one hundred tinet  [T]\n",
      "111 -> one hundred twnet  \n",
      "112 -> one hundred tweet  [T]\n",
      "113 -> one hundred tweetee  \n",
      "114 -> one hundred twenteen  [T]\n",
      "115 -> one hundred twenteen  \n",
      "116 -> one hundred twenty no  \n",
      "117 -> one hundred twenty no  [T]\n",
      "118 -> one hundred twenty no  [T]\n",
      "119 -> one hundred twenty no  \n",
      "120 -> one hundred twenty no  \n",
      "121 -> one hundred twenty ni  [T]\n",
      "122 -> one hundred twenty ni  [T]\n",
      "123 -> one hundred twenty ni  \n",
      "124 -> one hundred twenty ti  \n",
      "125 -> one hundred twenty ti  \n",
      "126 -> one hundred twenty ti  [T]\n",
      "127 -> one hundred twinty ti  \n",
      "128 -> one hundred twirty ti  \n",
      "129 -> one hundred thirty ti  [T]\n",
      "130 -> one hundred thirty ti  [T]\n",
      "131 -> one hundred thirty ti  \n",
      "132 -> one hundred thirty ti e  \n",
      "133 -> one hundred thirty ti e  [T]\n",
      "134 -> one hundred torrty tire  \n",
      "135 -> one hundred torryy tire  \n",
      "136 -> one hundred forty   i e  \n",
      "137 -> one hundred forty     e  [T]\n",
      "138 -> one hundred forty  hr  [T]\n",
      "139 -> one hundred forty  hr  \n",
      "140 -> one hundred forty thr  [T]\n",
      "141 -> one hundred forty thr  [T]\n",
      "142 -> one hundred forty thr  \n",
      "143 -> one hundred forty thr  [T]\n",
      "144 -> one hundred forty thu  [T]\n",
      "145 -> one hundred forty thu  \n",
      "146 -> one hundred fofty thu  \n",
      "147 -> one hundred fofty thu  [T]\n",
      "148 -> one hundred fofty thu  [T]\n",
      "149 -> one hundred fofty th  \n",
      "150 -> one hundred fofty th  [T]\n",
      "151 -> one hundred fifty th  \n",
      "152 -> one hundred fifty th  [T]\n",
      "153 -> one hundred fifty t  [T]\n",
      "154 -> one hundred fifty t  [T]\n",
      "155 -> one hundred fifty  \n",
      "156 -> one hundred fifty  [T]\n",
      "157 -> one hundred sixty  \n",
      "158 -> one hundred sixty  \n",
      "159 -> one hundred sixty  \n",
      "160 -> one hundred sixty  [T]\n",
      "161 -> one hundred sixty  \n",
      "162 -> one hundred sixty  \n",
      "163 -> one hundred sixty  [T]\n",
      "164 -> one hundred sixty  [T]\n",
      "165 -> one hundred sivty  \n",
      "166 -> one hundred sivtyy  \n",
      "167 -> one hundred sivtyt  \n",
      "168 -> one hundred sivtnt  \n",
      "169 -> one hundred siventy  i  [T]\n",
      "170 -> one hundred siventy  i  \n",
      "171 -> one hundred sivent   i  \n",
      "172 -> one hundred siveny   i  [T]\n",
      "173 -> one hundred siveny  \n",
      "174 -> one hundred sivety  [T]\n",
      "175 -> one hundred sivety  [T]\n",
      "176 -> one hundred sivety  \n",
      "177 -> one hundred sivety  [T]\n",
      "178 -> one hundred sivety  [T]\n",
      "179 -> one hundred sivety  [T]\n",
      "180 -> one hundred sivety  [T]\n",
      "181 -> one hundred sigety  \n",
      "182 -> one hundred sigety  [T]\n",
      "183 -> one hundred sigety  \n",
      "184 -> one hundred sigety  [T]\n",
      "185 -> one hundred sigety  [T]\n",
      "186 -> one hundred sigety  \n",
      "187 -> one hundred sigety  o  \n",
      "188 -> one hundred sigety  iu  \n",
      "189 -> one hundred sinety  iu  [T]\n",
      "190 -> one hundred ninety  iu  [T]\n",
      "191 -> one hundred ninety  iu  [T]\n",
      "192 -> one hundred ninety  iu  \n",
      "193 -> one hundred ninety  iu  [T]\n",
      "194 -> one hundred ninety  iu  [T]\n",
      "195 -> one hundred ninety  iue  [T]\n",
      "196 -> one hundred ninety  iue  [T]\n",
      "197 -> one hundred ninety  iue  [T]\n",
      "198 -> one hundred ninety  iue  \n",
      "199 -> one hundred ninety  iue  \n",
      "Correct 0 of 200  =  0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 200, 0.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label2words(label):\n",
    "    s = ''\n",
    "    for r in label:\n",
    "        s+=codes[int(r)]\n",
    "        #print(i,'->',s)\n",
    "    return s.strip()    \n",
    "    \n",
    "def check_model(verbose=0,show_training=1):\n",
    "    pred = model.predict(samples)\n",
    "    res = pred.argmax(axis=2)\n",
    "    correct = 0\n",
    "    for i in range(len(pred)):\n",
    "        if(not show_training and i in trainSamples): continue\n",
    "        train=''\n",
    "        if i in trainSamples: train='[T]'\n",
    "        txt = label2words(res[i])\n",
    "        txt_correct = getWords(i)\n",
    "        ok=''\n",
    "        if(txt==txt_correct): \n",
    "            correct+=1\n",
    "            ok = \"[ok]\"\n",
    "        if(verbose==1):\n",
    "            print(i,'->',txt, ok,train)\n",
    "    if verbose==0:\n",
    "        for i in range(10):        \n",
    "            x = random.randrange(DATASET_SIZE)\n",
    "            print(x,'->',label2words(res[x]))    \n",
    "    print('Correct',correct,'of',len(pred),' = ',(correct/len(pred)))\n",
    "    return correct,len(pred),(correct/len(pred))\n",
    "check_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_number2words.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input=188\n",
    "x = model.predict(np.array([input]))\n",
    "v = np.argmax(x,axis=2)\n",
    "#print(v.shape)\n",
    "print(label2words(v.ravel()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
